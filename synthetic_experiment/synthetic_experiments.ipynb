{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import pandas as pd\n",
    "import re\n",
    "import random\n",
    "from llm_response import (\n",
    "    OpenAILLMInvoker,\n",
    "    LLMResponse,\n",
    "    OpenAILLMConfig,\n",
    "    AnthropicLLMConfig,\n",
    "    AnthropicLLMInvoker,\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "import anthropic\n",
    "import scipy.stats as stats\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import openai\n",
    "\n",
    "def safe_api_call(openai, model, messages, stream=True, max_retries=20, initial_delay=2, **kwargs):\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # Pass additional kwargs to the API call, which can include 'temperature'\n",
    "            response = openai.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                stream=stream,\n",
    "                **kwargs  # This unpacks any additional arguments you've passed, such as 'temperature'\n",
    "            )\n",
    "            return response\n",
    "        except Exception as e:\n",
    "            print(f\"API Connection Error on attempt {attempt + 1}: {e}. Retrying after {initial_delay} seconds...\")\n",
    "            time.sleep(15)\n",
    "            #initial_delay *= 4  # Exponential backoff\n",
    "    raise Exception(\"All API call attempts failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#structural intervention distance (comparing difference between how intervention at one node changes subsequent nodes) adapted for chain graphs (max is 45, comes from 9+8+7+6.....1)\n",
    "\n",
    "def compute_extended_sid(graph1, graph2):\n",
    "    try:\n",
    "        graph1 = re.split(r' \\-> | - ', graph1)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        graph2 = re.split(r' \\-> | - ', graph2)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    # Function to generate a dictionary where each key is a node and its value is the set of nodes that can be reached from it\n",
    "    def generate_reachability_dict(graph):\n",
    "        reachability = {}\n",
    "        for i in range(len(graph)):\n",
    "            reachability[graph[i]] = set(graph[j] for j in range(i+1, len(graph)))\n",
    "        return reachability\n",
    "    \n",
    "    reach1 = generate_reachability_dict(graph1)\n",
    "    reach2 = generate_reachability_dict(graph2)\n",
    "    \n",
    "    # Identify the set of common nodes in both graphs\n",
    "    #common_nodes = set(graph1) & set(graph2)\n",
    "\n",
    "    # Remove nodes not in both graphs\n",
    "    #reach1 = {node: reach1[node] for node in common_nodes}\n",
    "    #reach2 = {node: reach2[node] for node in common_nodes}\n",
    "    \n",
    "    # Calculate SID by comparing the differences in reachability for each node between the two graphs\n",
    "    sid = 0\n",
    "    for node in set(graph1) | set(graph2):  # Union of nodes in both graphs\n",
    "        affected_nodes1 = reach1.get(node, set())\n",
    "        affected_nodes2 = reach2.get(node, set())\n",
    "        \n",
    "        # The difference in affected nodes for interventions at the same node between the two graphs\n",
    "        sid += len(affected_nodes1.difference(affected_nodes2))\n",
    "    return (sid, sid/sum(range(1, len(set(graph1) | set(graph2)))), len(set(graph1) | set(graph2)) - len(set(graph1))  )\n",
    "\n",
    "# Compute the extended SID considering the impact on all subsequent nodes\n",
    "#extended_sid_value = compute_extended_sid(listSameLLM2, listTenE)\n",
    "#extended_sid_value\n",
    "\n",
    "#Contribution of picking a wrong node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def confidence_interval(data, confidence=0.95):\n",
    "    n = len(data)\n",
    "    mean = np.mean(data)\n",
    "    sem = stats.sem(data)  # Standard error of the mean\n",
    "    margin = sem * stats.t.ppf((1 + confidence) / 2., n-1)  # T-distribution critical value\n",
    "    return mean, mean - margin, mean + margin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is a test of parametric knowledge (causal v anticausal)\n",
    "def parametric_test(causal=False,chain = False, context = False, narr_graph = False):\n",
    "    OeventList = []\n",
    "    OtenEList = []\n",
    "    OsameLLM1List = []\n",
    "    Oacc_list = []\n",
    "    Ocon_list = []\n",
    "    Oint_diff =[]\n",
    "    Onarr_list =[]\n",
    "\n",
    "\n",
    "    num_iters = 10\n",
    "    i=0\n",
    "    counter = 0 \n",
    "\n",
    "    #First loop is for chain length\n",
    "    for j in range(4,22,4):\n",
    "        \n",
    "        numItems = j\n",
    "        print(\"_______________________________________________:\",j)\n",
    "        #Tracker Variables\n",
    "        eventList = []\n",
    "        tenEList = []\n",
    "        sameLLM1List = []\n",
    "        acc_list = []\n",
    "        con_list = []\n",
    "        int_diff = []\n",
    "        narr_list = []\n",
    "        for counter in range(num_iters):\n",
    "            \n",
    "            #Creating Seed events \n",
    "            if (causal==True):\n",
    "                stream = safe_api_call(\n",
    "                openai=openai,\n",
    "                model=\"gpt-4\",\n",
    "                messages=[{\"role\": \"user\", \"content\": \"generate 30 events that cause each other (for example the first event causes the second and the second causes the third)\"}],\n",
    "                stream=True\n",
    "            )\n",
    "            else:\n",
    "                stream = safe_api_call(\n",
    "                openai=openai,\n",
    "                model=\"gpt-4\",\n",
    "                messages=[{\"role\": \"user\", \"content\": \"generate 30 events that are anticausal, for example the first event could be cancer and the second event could be a longer life \" +\n",
    "                           \"because in reality, cancer causes a shorter life. Make it so each of the 30 events are anticausal in this way such that the next event is actually the opposite of what it should be \" +\n",
    "                           \"For 3 events we might have 1.Rain 2.Plants Die 3.Increased Oxygen\"}],\n",
    "                stream=True\n",
    "            )\n",
    "\n",
    "            events = \"\"\n",
    "            for a, chunk in enumerate(stream):\n",
    "                if (chunk.choices[0].delta.content is not None):\n",
    "                    events += chunk.choices[0].delta.content\n",
    "            \n",
    "            result_list = [re.sub(r'^\\d+\\.\\s*', '', line.strip()) for line in events.split('\\n')]\n",
    "            result_list\n",
    "            list1 = result_list[::2]  # First, third, fifth, etc. (odd-indexed)\n",
    "            list2 = result_list[1::2] # Second, fourth, sixth, etc. (even-indexed)\n",
    "\n",
    "            new_list = list1[:int(numItems/2)] + list2[:int(numItems/2)]\n",
    "\n",
    "            \n",
    "            #Creating Ground Truth Graph (Forward)\n",
    "            stream = safe_api_call(\n",
    "                openai = openai,\n",
    "            model=\"gpt-4\",\n",
    "            messages=[{\"role\": \"user\", \"content\":  \"context is \" +str(new_list) + \" generate a causal chain graph connecting them (dont include numbers with the items).\"+\n",
    "                    \"The output should be in the form of a chain graph with only items from \" +str(new_list) +\" , the output should have \"+str(numItems)+ \" nodes in it that sequentially connected with edges, seperate nodes with a  ->\"}],\n",
    "            stream=True,\n",
    "            temperature=0\n",
    "            )\n",
    "            tenE = \"\"\n",
    "            for b, chunk in enumerate(stream):\n",
    "                if (chunk.choices[0].delta.content is not None):\n",
    "                    tenE += chunk.choices[0].delta.content\n",
    "                    \n",
    "            list_tenE= re.split(r' \\-> | - ', tenE)\n",
    "            if (len(list_tenE) != numItems):\n",
    "                pass\n",
    "            #print(list_tenE)\n",
    "            #Creating Narrative\n",
    "            stream = safe_api_call(\n",
    "            openai = openai,\n",
    "            model=\"gpt-4\",\n",
    "            messages=[{\"role\": \"user\", \"content\":  \"context is\" +tenE +\"generate a hypothetical narrative from this causal chain graph and make causal relations explicit, even when the causal relations \" +\n",
    "                       \"do not make sense, keep the causal relations as they were in the context. The events in the story should occur in the same order as in the chain graph (eg first item in chain graph should appear in narrative before the second item)\"}],\n",
    "            stream=True,\n",
    "            )\n",
    "            originalNarrative = \"\"\n",
    "            for c, chunk in enumerate(stream):\n",
    "                if (chunk.choices[0].delta.content is not None):\n",
    "                    originalNarrative += chunk.choices[0].delta.content\n",
    "            print(list_tenE)\n",
    "            print(originalNarrative)\n",
    "            stream = safe_api_call(\n",
    "                openai = openai,\n",
    "            model=\"gpt-4\",\n",
    "            messages=[{\"role\": \"user\", \"content\":  \"generate a causal chain graph with \"+str(numItems)+ \" nodes from this narrative \" +originalNarrative +\"only using items from this list:\"\n",
    "                    +events+\"(dont include numbers with the items), the output should have \"+str(numItems)+ \" nodes in it that sequentially connected with edges, seperate nodes with a  -> \"}],\n",
    "            stream=True,\n",
    "            )\n",
    "            sameLLM1 = \"\"\n",
    "            for d, chunk in enumerate(stream):\n",
    "                if (chunk.choices[0].delta.content is not None):\n",
    "                    sameLLM1 += chunk.choices[0].delta.content\n",
    "        \n",
    "            list_SameLLM1 = re.split(r' \\-> | - ', sameLLM1)\n",
    "            #print(\"1\")\n",
    "            #print(list_SameLLM1)\n",
    "            unique_nodes = list(set(list_SameLLM1) | set(list_tenE))\n",
    "\n",
    "            truth_list = [] \n",
    "            consistency_list = []\n",
    "            query_list = []\n",
    "            for i in range(0,10):\n",
    "                try:\n",
    "                    int1= random.randint(0,int(numItems/2)+1)\n",
    "                    #print(int1) \n",
    "                    int2 = int1 + int(numItems/2)\n",
    "                    #print(int2) \n",
    "                    uniNodesEvent1 = list_tenE[int1]\n",
    "                    uniNodesEvent2 = list_tenE[int2]\n",
    "                    query_list.append((uniNodesEvent1,uniNodesEvent2 ))\n",
    "\n",
    "                  \n",
    "                    if int1 < int2:\n",
    "                        truth_list.append(2)\n",
    "                    else:\n",
    "                        truth_list.append(1)\n",
    "                    \n",
    "                    try:\n",
    "                        index1 = list_SameLLM1.index(uniNodesEvent1)\n",
    "                    except:\n",
    "                        index1 = -1\n",
    "                    try:\n",
    "                        index2= list_SameLLM1.index(uniNodesEvent2)\n",
    "                    except:\n",
    "                        index2= -1\n",
    "\n",
    "                    if index1 < index2:\n",
    "                        consistency_list.append(2)\n",
    "                    else:\n",
    "                        consistency_list.append(1)\n",
    "                except:\n",
    "                    pass\n",
    "           \n",
    "                        #print(\"Point 2\")\n",
    "           \n",
    "            \n",
    "            print(query_list)\n",
    "\n",
    "            def extract_answer(text):\n",
    "                # Regular expression to match content between <answer> and </answer> tags\n",
    "                match = re.search(r'<answer>(Yes|No)</answer>', text)\n",
    "                if match:\n",
    "                    return match.group(1)  # Returns either 'Yes' or 'No'\n",
    "                else:\n",
    "                    return None  # If no match is found\n",
    "               \n",
    "            comp = []\n",
    "            for item in query_list:\n",
    "                if (chain == True):\n",
    "                    q =   \"Use this narrative \"+ originalNarrative + \" as context Did \"+ item[0 ]+ \" cause \" + item[1] +\\\n",
    "                    \" ? Do step by step reasoning. Then output your answer with <answer>Yes/No</answer>\"\n",
    "                elif (context==True):\n",
    "                    q =  \"Use this narrative \"+ originalNarrative+\\\n",
    "                \" as context. Did \"+ item[0]+ \" cause \" + item[1] +\\\n",
    "                    \" ? Output your answer with <answer>Yes/No</answer>. The cause can be direct or indirect.\" +\\\n",
    "                    \"An example narrative would be: Rains leads to plants growing. This then causes increased oxygen in the atmosphere. A potential question would be does Rain cause increased oxygen in the atmosphere? The answer would be Yes.\" +\\\n",
    "                    \"Another example narrative would be: Increased oxygen in the atmosphere is because of plants growing. Plants grow because rain provides them essential nutrients. A potential question would be does Rain cause increased oxygen in the atmosphere? The answer would be Yes.\" +\\\n",
    "                    \"Another example narrative would be: Rain leads plants to grow. Plants growing causes less oxygen in the atmosphere. A potential question would be does Rain cause less oxygen in the atmosphere? The answer would be Yes.\"\n",
    "                elif (narr_graph == True):\n",
    "                    q =    \"Use this narrative \"+ originalNarrative + \" and this causal ordering \" +  str(sameLLM1) +\\\n",
    "                      \"(such that each item is a cause of every item after it, for example the first list item is a cause of the third, fourth, fifth items etc)\" +\\\n",
    "                \" as context. Did \"+ item[0]+ \" cause \" + item[1] +\\\n",
    "                    \" ? Output only <answer>Yes/No</answer>. The cause can be direct or indirect\"\n",
    "                else:\n",
    "                    q =    \"Use this narrative \"+ originalNarrative + \" as context. Did \"+ item[0 ]+ \" cause \" + item[1] +\\\n",
    "                    \"? Output only <answer>Yes/No</answer>. The cause can be indirect or direct\"  \n",
    "                stream = safe_api_call(\n",
    "                        openai = openai,\n",
    "                model=\"gpt-4\",\n",
    "                messages=[{\"role\": \"user\", \"content\": q }],\n",
    "                stream=True,\n",
    "                )\n",
    "\n",
    "                #print(q)\n",
    "                answer = \"\"\n",
    "                for f, chunk in enumerate(stream):\n",
    "                    if (chunk.choices[0].delta.content is not None):\n",
    "                        answer += chunk.choices[0].delta.content\n",
    "                print(answer)\n",
    "                comp.append(extract_answer(answer))\n",
    "                \n",
    "     \n",
    "\n",
    "            try:\n",
    "                print(comp)\n",
    "                #print(\"Point 3\")\n",
    "                qList =  [x for x in comp if x!=\"\"]\n",
    "                qList =  [x for x in qList if x!=\".\"]\n",
    "                #print(qList)\n",
    "                dictt = {\"Yes\":2, \"No\":1,\"yes\":2, \"no\":1}\n",
    "                qList = [dictt[x] for x in qList]\n",
    "                qList =[int(x) for x in qList]\n",
    "                print(qList)\n",
    "                print(truth_list)\n",
    "                acc = sum(1 for x, y in zip(truth_list, qList) if x == y)/len(qList)\n",
    "                con_score = sum(1 for x, y in zip(consistency_list, qList) if x == y)/len(qList)\n",
    "                #consistency = sum(1 for x, y in zip(consistency_list, qList) if x == y)\n",
    "                #con_score = consistency/len(qList) \n",
    "                con_list.append(con_score)\n",
    "                acc_list.append(acc)\n",
    "                eventList.append(events)\n",
    "                tenEList.append(tenE)\n",
    "                print(\"counter\", counter)\n",
    "                int_diff.append(int2-int1)\n",
    "                narr_list.append(originalNarrative)\n",
    "                sameLLM1List.append(list_SameLLM1)\n",
    "            except:\n",
    "                pass\n",
    "        OeventList.append(eventList)\n",
    "        OtenEList.append(tenEList)\n",
    "        Oint_diff.append(int_diff)\n",
    "        Ocon_list.append(con_list)\n",
    "        Oacc_list.append(acc_list)\n",
    "        Onarr_list.append(narr_list)\n",
    "        OsameLLM1List.append(sameLLM1List)\n",
    "    \n",
    "    return (OeventList, OtenEList, Oacc_list, Oint_diff,Ocon_list,Onarr_list, OsameLLM1List )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This test topological ordering\n",
    "def topological(reverse= False, forward = False, chain = False, context = False, narr_graph = False)):\n",
    "    OeventList = []\n",
    "    OtenEList = []\n",
    "    OsameLLM1List = []\n",
    "    Oacc_list = []\n",
    "    Ocon_list = []\n",
    "    Oint_diff =[]\n",
    "    Onarr_list =[]\n",
    "\n",
    "\n",
    "\n",
    "    num_iters = 10\n",
    "    i=0\n",
    "    counter = 0 \n",
    "\n",
    "    #First loop is for chain length\n",
    "    for j in range(4,22,4):\n",
    "        \n",
    "        numItems = j\n",
    "        print(\"_______________________________________________:\",j)\n",
    "        #Tracker Variables\n",
    "        eventList = []\n",
    "        tenEList = []\n",
    "        sameLLM1List = []\n",
    "        acc_list = []\n",
    "        con_list = []\n",
    "        int_diff = []\n",
    "        narr_list = []\n",
    "        for counter in range(num_iters):\n",
    "            \n",
    "            stream = safe_api_call(\n",
    "                openai=openai,\n",
    "                model=\"gpt-4\",\n",
    "                messages=[{\"role\": \"user\", \"content\": \"generate 100 random distinct events\"}],\n",
    "                stream=True\n",
    "            )\n",
    "            events = \"\"\n",
    "            for a, chunk in enumerate(stream):\n",
    "                if (chunk.choices[0].delta.content is not None):\n",
    "                    events += chunk.choices[0].delta.content\n",
    "            \n",
    "            #Creating Ground Truth Graph (Forward)\n",
    "            stream = safe_api_call(\n",
    "                openai = openai,\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\":  \"context is\" +events +\"randomly pick\"+str(numItems)+ \"items from this list and generate a causal chain graph connecting them (dont include numbers with the items).\"+\n",
    "                    \"The output should be in the form of a chain graph with only items from the 100 items, the output should have \"+str(numItems)+ \" nodes in it that sequentially connected with edges, seperate nodes with a  ->\"}],\n",
    "            stream=True,\n",
    "            temperature=0\n",
    "            )\n",
    "            tenE = \"\"\n",
    "            for b, chunk in enumerate(stream):\n",
    "                if (chunk.choices[0].delta.content is not None):\n",
    "                    tenE += chunk.choices[0].delta.content\n",
    "\n",
    "            if (reverse==True):\n",
    "            #Creating Reverse Narrative\n",
    "                stream = safe_api_call(\n",
    "                openai = openai,\n",
    "                model=\"gpt-4\",\n",
    "                messages=[{\"role\": \"user\", \"content\":  \"context is\" +tenE +\"generate a hypothetical narrative from this causal chain graph and make causal relations explicit, even when the causal relations \" +\n",
    "                       \"do not make sense, keep the causal relations as they were in the context. The events in the story should occur in the opposite order as in the chain graph (eg last item in chain graph should appear first in the  narrative etc)\"}],\n",
    "                stream=True,\n",
    "                )\n",
    "                originalNarrative = \"\"\n",
    "                for c, chunk in enumerate(stream):\n",
    "                    if (chunk.choices[0].delta.content is not None):\n",
    "                        originalNarrative += chunk.choices[0].delta.content\n",
    "            \n",
    "            if (forward==True):\n",
    "                #Creating Narrative\n",
    "                stream = safe_api_call(\n",
    "                openai = openai,\n",
    "                model=\"gpt-4\",\n",
    "                messages=[{\"role\": \"user\", \"content\":  \"context is\" +tenE +\"generate a hypothetical narrative from this causal chain graph and make causal relations explicit, even when the causal relations \" +\n",
    "                       \"do not make sense, keep the causal relations as they were in the context. The events in the story should occur in the same as in the chain graph (eg first item in chain graph should appear in narrative before the second item)\"}],\n",
    "                stream=True,\n",
    "                )\n",
    "                originalNarrative = \"\"\n",
    "                for c, chunk in enumerate(stream):\n",
    "                    if (chunk.choices[0].delta.content is not None):\n",
    "                        originalNarrative += chunk.choices[0].delta.content\n",
    "\n",
    "\n",
    "            stream = safe_api_call(\n",
    "                openai = openai,\n",
    "            model=\"gpt-4\",\n",
    "            messages=[{\"role\": \"user\", \"content\":  \"generate a causal chain graph with \"+str(numItems)+ \" nodes from this narrative \" +originalNarrative +\"only using items from this list:\"\n",
    "                    +events+\"(dont include numbers with the items), the output should have \"+str(numItems)+ \" nodes in it that sequentially connected with edges, seperate nodes with a  -> \"}],\n",
    "            stream=True,\n",
    "            )\n",
    "            sameLLM1 = \"\"\n",
    "            for d, chunk in enumerate(stream):\n",
    "                if (chunk.choices[0].delta.content is not None):\n",
    "                    sameLLM1 += chunk.choices[0].delta.content\n",
    "\n",
    "\n",
    "            list_tenE = re.split(r' \\-> | - ', tenE)\n",
    "            list_SameLLM1 = re.split(r' \\-> | - ', sameLLM1)\n",
    "            #print(\"1\")\n",
    "            #print(list_SameLLM1)\n",
    "            unique_nodes = list(set(list_SameLLM1) | set(list_tenE))\n",
    "\n",
    "            truth_list = [] \n",
    "            consistency_list = []\n",
    "            query_list = []\n",
    "\n",
    "\n",
    "            \n",
    "                        \n",
    "\n",
    "            \n",
    "            for i in range(0,10):\n",
    "                try:\n",
    "                    int1, int2 = random.sample(range(0, len(list_tenE)), 2)  \n",
    "                    uniNodesEvent1 = list_tenE[int1]\n",
    "                    uniNodesEvent2 = list_tenE[int2]\n",
    "                    query_list.append((uniNodesEvent1,uniNodesEvent2 ))\n",
    "    \n",
    "                    if int1 < int2:\n",
    "                        truth_list.append(2)\n",
    "                    else:\n",
    "                        truth_list.append(1)\n",
    "                    \n",
    "                    try:\n",
    "                        index1 = list_SameLLM1.index(uniNodesEvent1)\n",
    "                    except:\n",
    "                        index1 = -1\n",
    "                    try:\n",
    "                        index2= list_SameLLM1.index(uniNodesEvent2)\n",
    "                    except:\n",
    "                        index2= -1\n",
    "\n",
    "                    if index1 < index2:\n",
    "                        consistency_list.append(2)\n",
    "                    else:\n",
    "                        consistency_list.append(1)\n",
    "                except:\n",
    "                    pass\n",
    "           \n",
    "                        #print(\"Point 2\")\n",
    "           \n",
    "            print(query_list)\n",
    "\n",
    "            def extract_answer(text):\n",
    "                # Regular expression to match content between <answer> and </answer> tags\n",
    "                match = re.search(r'<answer>(Yes|No)</answer>', text)\n",
    "                if match:\n",
    "                    return match.group(1)  # Returns either 'Yes' or 'No'\n",
    "                else:\n",
    "                    return None  # If no match is found\n",
    "                               \n",
    "            comp = []\n",
    "            for item in query_list:\n",
    "                if (chain == True):\n",
    "                    q =   \"Use this narrative \"+ originalNarrative + \" as context Did \"+ item[0 ]+ \" cause \" + item[1] +\\\n",
    "                    \" ? Do step by step reasoning. Then output your answer with <answer>Yes/No</answer>. The cause can be direct or indirect.\"\n",
    "                elif (context==True):\n",
    "                    q =  \"Use this narrative \"+ originalNarrative+\\\n",
    "                \" as context. Did \"+ item[0]+ \" cause \" + item[1] +\\\n",
    "                    \" ? Output your answer with <answer>Yes/No</answer>. The cause can be direct or indirect.\" +\\\n",
    "                    \"An example narrative would be: Rains leads to plants growing. This then causes increased oxygen in the atmosphere. A potential question would be does Rain cause increased oxygen in the atmosphere? The answer would be Yes.\" +\\\n",
    "                    \"Another example narrative would be: Increased oxygen in the atmosphere is because of plants growing. Plants grow because rain provides them essential nutrients. A potential question would be does Rain cause increased oxygen in the atmosphere? The answer would be Yes.\" +\\\n",
    "                    \"Another example narrative would be: Rain leads plants to grow. Plants growing causes less oxygen in the atmosphere. A potential question would be does Rain cause less oxygen in the atmosphere? The answer would be Yes.\"\n",
    "                elif (narr_graph == True):\n",
    "                    q =    \"Use this narrative \"+ originalNarrative + \" and this causal ordering \" +  str(sameLLM1) +\\\n",
    "                      \"(such that each item is a cause of every item after it, for example the first list item is a cause of the third, fourth, fifth items etc)\" +\\\n",
    "                \" as context. Did \"+ item[0]+ \" cause \" + item[1] +\\\n",
    "                    \" ? Output only <answer>Yes/No</answer>. The cause can be direct or indirect\"\n",
    "                else:\n",
    "                    q =    \"Use this narrative \"+ originalNarrative + \" as context. Did \"+ item[0 ]+ \" cause \" + item[1] +\\\n",
    "                    \"? Output only <answer>Yes/No</answer>. The cause can be indirect or direct\"  \n",
    "                stream = safe_api_call(\n",
    "                        openai = openai,\n",
    "                model=\"gpt-4\",\n",
    "                messages=[{\"role\": \"user\", \"content\": q }],\n",
    "                stream=True,\n",
    "                )\n",
    "\n",
    "                #print(q)\n",
    "                answer = \"\"\n",
    "                for f, chunk in enumerate(stream):\n",
    "                    if (chunk.choices[0].delta.content is not None):\n",
    "                        answer += chunk.choices[0].delta.content\n",
    "                print(answer)\n",
    "                comp.append(extract_answer(answer))\n",
    "                \n",
    "     \n",
    "\n",
    "            try:\n",
    "                print(comp)\n",
    "                #print(\"Point 3\")\n",
    "                qList =  [x for x in comp if x!=\"\"]\n",
    "                qList =  [x for x in qList if x!=\".\"]\n",
    "                #print(qList)\n",
    "                dictt = {\"Yes\":2, \"No\":1,\"yes\":2, \"no\":1}\n",
    "                qList = [dictt[x] for x in qList]\n",
    "                qList =[int(x) for x in qList]\n",
    "                print(qList)\n",
    "                print(truth_list)\n",
    "                acc = sum(1 for x, y in zip(truth_list, qList) if x == y)/len(qList)\n",
    "                con_score = sum(1 for x, y in zip(consistency_list, qList) if x == y)/len(qList)\n",
    "                #consistency = sum(1 for x, y in zip(consistency_list, qList) if x == y)\n",
    "                #con_score = consistency/len(qList) \n",
    "                con_list.append(con_score)\n",
    "                acc_list.append(acc)\n",
    "                eventList.append(events)\n",
    "                tenEList.append(tenE)\n",
    "                print(\"counter\", counter)\n",
    "                int_diff.append(int2-int1)\n",
    "                narr_list.append(originalNarrative)\n",
    "                sameLLM1List.append(list_SameLLM1)\n",
    "            except:\n",
    "                pass\n",
    "        OeventList.append(eventList)\n",
    "        OtenEList.append(tenEList)\n",
    "        Oint_diff.append(int_diff)\n",
    "        Ocon_list.append(con_list)\n",
    "        Oacc_list.append(acc_list)\n",
    "        Onarr_list.append(narr_list)\n",
    "        OsameLLM1List.append(sameLLM1List)\n",
    "    \n",
    "    return (OeventList, OtenEList, Oacc_list, Oint_diff,Ocon_list,Onarr_list, OsameLLM1List )"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
